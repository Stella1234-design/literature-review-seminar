---
layout: default
title: "Session 2: Qualities and tools (teaching notes)"
has_toc: true
nav_exclude: true
search_exclude: true
---

# Session 2: Qualities and tools (teaching notes)

## Qualities

Given that transparency is significant, why do some reviews not report their methods explicitly? For example, Alavi and Leidner (2001). Try to take their position and argue why a methods section would not be helpful for their work.

### Reporting standards

Discuss: which aspects of systematicity/transparency are important for your review, which ones will you skip?

### Theoretical contributions

Study specific exemplars

**TODO : add Rivard 2024 JSIS**

 TODO : ideally, link to an overview of IS review papers (filtered for impact) 
scholarship

### Research agenda

Application: read exemplars of research agendas, discuss the key elements, how you research agenda could be developed

The impact of a research agenda: Foresight (research agenda) -> Scientific impact

### Summary

Note: theoretical or empirical contribution: not based on the evidence.
-> we can assume that highly transparent papers that lack a contribution will not be cited.

## Tools

Start with a question on students' current thoughts about tool selection in their review protocol.

Warm-up: have you worked with research software, what should the ideal literature review tools offer?

### Self-managed approach: Tools

TODO : add connectedpapers/inciteful
mention asreview / the spiral model:
https://link.springer.com/article/10.1186/s13643-023-02421-z


#### Colrev

TODO : include comparison (readme)!

- OpenSource, extensible, validated, cost-efficient (open research software, e.g., R/Tidyverse, Machine Learning in Python, Visualization)
Note: low-code / code environment

Highlight that literature review data may be different from typical "reproducible research approaches". Why?
-> Explain the different properties (LRDM), Git

Explicitly show the colrev status

Show the data (that is what CoLRev relies on)

Invite students to contribute to CoLRev (documentation, testing, etc.)

### LLMs, current challenges, and promises

- LLM like ChatGPT are seemingly easy to operate (simple interface), but generating useful output is surprisingly hard (a metaphorical Norman door)
- litmaps

### Which developments can be anticipated?


(not formally part of the main review steps)
 e.g., tabulating  - give examples 
 
effectively excluding over 90% of the information and only considering a few words of each PDF

-> we may even illustrate this with a whole paper and the title highlighted for screening

**Philosophical questions**

- makes researchers obsolete
- danger that it reduces deep engagement with prior literature (opportunity to preserve that ability)

## Outlook

Create a reminder for the presentation session

# Thank you!

The nice thing about literature reviews is that there are many roads that may connect us (or colleagues)

- Deep engagement (AI/generative AI? - reading not part of the process?)
-> How could ML/machines/generative AI facilitate a deeper understanding (instead of distancing reviewers from the literature)?

Wrap-up! Plans for submission (presentation?!?!)